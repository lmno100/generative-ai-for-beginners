{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMh2/vJoOqyeXbEHL5+/NpN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff298b672cef4caab82cdd3f177111eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_703481bcae4e4cb497d10cb3df94be31",
              "IPY_MODEL_0bc7a995aa234f15a1b02eb42a5bcc07",
              "IPY_MODEL_e4c982bb385e4cfd82a48890d7201f1c"
            ],
            "layout": "IPY_MODEL_14c2c706e43648c6ac09b2bde6913e35"
          }
        },
        "703481bcae4e4cb497d10cb3df94be31": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_350f0d5f6a5a4137b20583cee0162ebb",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "You: hey\n"
                ]
              },
              {
                "output_type": "error",
                "ename": "TypeError",
                "evalue": "all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, tuple of ints dim = None, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, name dim, bool keepdim = False, *, Tensor out = None)\n",
                "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                  "\u001b[0;32m<ipython-input-13-9f496750c501>\u001b[0m in \u001b[0;36mon_send\u001b[0;34m(self, _)\u001b[0m\n\u001b[1;32m    104\u001b[0m            \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You: {user_input}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meliza_bot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Eliza: {response}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m<ipython-input-13-9f496750c501>\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, input_text, max_length, min_length, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ELIZA:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_extra_spaces_and_line_breaks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m<ipython-input-13-9f496750c501>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(self, encoded_input, max_length, min_length, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0mstopping_criteria_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStoppingCriteriaList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStoppingCriteriaSub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_token_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopping_criteria\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstopping_criteria_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2253\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3308\u001b[0m                 \u001b[0mstreamer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3310\u001b[0;31m             \u001b[0munfinished_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munfinished_sequences\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mstopping_criteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3311\u001b[0m             \u001b[0mthis_peer_finished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munfinished_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3312\u001b[0m             \u001b[0mcur_len\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/stopping_criteria.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mis_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcriteria\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mis_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_done\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m<ipython-input-13-9f496750c501>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;31mTypeError\u001b[0m: all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, tuple of ints dim = None, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, name dim, bool keepdim = False, *, Tensor out = None)\n"
                ]
              }
            ]
          }
        },
        "0bc7a995aa234f15a1b02eb42a5bcc07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5fda6af691c4897a396d057ecb0d317",
              "IPY_MODEL_e542969977f64dbeb23823e76099e04e"
            ],
            "layout": "IPY_MODEL_b242d049bec14e6899400d24de57c730"
          }
        },
        "e4c982bb385e4cfd82a48890d7201f1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_025f4038434e4763b247099a3e576503",
              "IPY_MODEL_6c990985d0aa47f191c0c7c2322d6fab"
            ],
            "layout": "IPY_MODEL_5285f975274943b2bb63d2a1c36f543b"
          }
        },
        "14c2c706e43648c6ac09b2bde6913e35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5fda6af691c4897a396d057ecb0d317": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "You:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_2416415299a24657b01fbeb0c2782d5c",
            "placeholder": "Type your message here",
            "style": "IPY_MODEL_37233b15db36446d9618e1bded185a04",
            "value": ""
          }
        },
        "e542969977f64dbeb23823e76099e04e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Send",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4d193158f2f447b0b998965aa65ae1d2",
            "style": "IPY_MODEL_e51eb9f2ee544260ac643d5afbeab6b4",
            "tooltip": ""
          }
        },
        "b242d049bec14e6899400d24de57c730": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "025f4038434e4763b247099a3e576503": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Clear",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_09b1bfe99b3144c5a30bd2031500b70e",
            "style": "IPY_MODEL_5e9630cb610b453680b4a9d0537e8327",
            "tooltip": ""
          }
        },
        "6c990985d0aa47f191c0c7c2322d6fab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Stop",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_7bbcdff024c14be18871b72b2be2220e",
            "style": "IPY_MODEL_d2ac2a22947e46b4b5d9173829d9d578",
            "tooltip": ""
          }
        },
        "5285f975274943b2bb63d2a1c36f543b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2416415299a24657b01fbeb0c2782d5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37233b15db36446d9618e1bded185a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d193158f2f447b0b998965aa65ae1d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e51eb9f2ee544260ac643d5afbeab6b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "09b1bfe99b3144c5a30bd2031500b70e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e9630cb610b453680b4a9d0537e8327": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "7bbcdff024c14be18871b72b2be2220e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d2ac2a22947e46b4b5d9173829d9d578": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "350f0d5f6a5a4137b20583cee0162ebb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac757a68aa0a405f89a8bce545838ee2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_85340d8b00ea44d1859f2da7b6aebbd9",
              "IPY_MODEL_113032abc9cf4c3b8ea276a0f04b2d45",
              "IPY_MODEL_544ecbbebb3d48afb97705621909169f"
            ],
            "layout": "IPY_MODEL_15f02b54646b4ab9b5b091290bb5e6aa"
          }
        },
        "85340d8b00ea44d1859f2da7b6aebbd9": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_d35999a44db14c2fae7c1b6a665484f8",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                  "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "You: whos this? \n"
                ]
              },
              {
                "output_type": "error",
                "ename": "TypeError",
                "evalue": "all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, tuple of ints dim = None, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, name dim, bool keepdim = False, *, Tensor out = None)\n",
                "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
                  "\u001b[0;32m<ipython-input-15-498d657e3e53>\u001b[0m in \u001b[0;36mon_send\u001b[0;34m(self, _)\u001b[0m\n\u001b[1;32m    111\u001b[0m            \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You: {user_input}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meliza_bot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Eliza: {response}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m<ipython-input-15-498d657e3e53>\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, input_text, max_length, min_length, **kwargs)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ELIZA:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_extra_spaces_and_line_breaks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m<ipython-input-15-498d657e3e53>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(self, encoded_input, max_length, min_length, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0mstopping_criteria_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStoppingCriteriaList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStoppingCriteriaSub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_token_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                 \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopping_criteria\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstopping_criteria_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m                 \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   2250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2251\u001b[0m             \u001b[0;31m# 12. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2252\u001b[0;31m             result = self._sample(\n\u001b[0m\u001b[1;32m   2253\u001b[0m                 \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2254\u001b[0m                 \u001b[0mlogits_processor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprepared_logits_processor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, **model_kwargs)\u001b[0m\n\u001b[1;32m   3308\u001b[0m                 \u001b[0mstreamer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_tokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3310\u001b[0;31m             \u001b[0munfinished_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munfinished_sequences\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m~\u001b[0m\u001b[0mstopping_criteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3311\u001b[0m             \u001b[0mthis_peer_finished\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munfinished_sequences\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3312\u001b[0m             \u001b[0mcur_len\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/generation/stopping_criteria.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m    494\u001b[0m         \u001b[0mis_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcriteria\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0mis_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_done\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcriteria\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mis_done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m<ipython-input-15-498d657e3e53>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, input_ids, scores, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstop\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;31mTypeError\u001b[0m: all() received an invalid combination of arguments - got (bool), but expected one of:\n * (Tensor input, *, Tensor out = None)\n * (Tensor input, tuple of ints dim = None, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, int dim, bool keepdim = False, *, Tensor out = None)\n * (Tensor input, name dim, bool keepdim = False, *, Tensor out = None)\n"
                ]
              }
            ]
          }
        },
        "113032abc9cf4c3b8ea276a0f04b2d45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b0e3e11f9e694ac2b7e0f5f9f30dc29d",
              "IPY_MODEL_eb764e8934d2422a8d50315463af8505"
            ],
            "layout": "IPY_MODEL_ea625e433a2e423f918a14087ce4fb70"
          }
        },
        "544ecbbebb3d48afb97705621909169f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a7f3ed5d6f194ab6b7ee6c2d65da55d3",
              "IPY_MODEL_186e6dc580144ce6b58ce2e45d92b904"
            ],
            "layout": "IPY_MODEL_675b57dd2a54441f8880398976d20a1f"
          }
        },
        "15f02b54646b4ab9b5b091290bb5e6aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0e3e11f9e694ac2b7e0f5f9f30dc29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "You:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b71b74f324e6409c809e172498d07c62",
            "placeholder": "Type your message here",
            "style": "IPY_MODEL_fdb4b367466e45569fd4291f36e8cc30",
            "value": ""
          }
        },
        "eb764e8934d2422a8d50315463af8505": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Send",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_075933477c8c4e27abc82c2a03aeec13",
            "style": "IPY_MODEL_d3ec064de1fb479bae5bd2af6699cb79",
            "tooltip": ""
          }
        },
        "ea625e433a2e423f918a14087ce4fb70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7f3ed5d6f194ab6b7ee6c2d65da55d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Clear",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8801940601db417cb205b60e30fa5f54",
            "style": "IPY_MODEL_edfe37c319dd477f808c8fb6ea5b2923",
            "tooltip": ""
          }
        },
        "186e6dc580144ce6b58ce2e45d92b904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Stop",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_370f12f55a784956ab7c9d900df63035",
            "style": "IPY_MODEL_c46aa4dba8924f84adf3485b0ba6bc3d",
            "tooltip": ""
          }
        },
        "675b57dd2a54441f8880398976d20a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71b74f324e6409c809e172498d07c62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdb4b367466e45569fd4291f36e8cc30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "075933477c8c4e27abc82c2a03aeec13": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3ec064de1fb479bae5bd2af6699cb79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "8801940601db417cb205b60e30fa5f54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edfe37c319dd477f808c8fb6ea5b2923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "370f12f55a784956ab7c9d900df63035": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c46aa4dba8924f84adf3485b0ba6bc3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d35999a44db14c2fae7c1b6a665484f8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab1ee86faf1742e28abce194da96e6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce72b35efd00414cabbfa4388ba8090a",
              "IPY_MODEL_3d07609887ff463db060510a81cc49e1",
              "IPY_MODEL_62cb2396d6ce443aa41ca5fbd85cfacf"
            ],
            "layout": "IPY_MODEL_233cd86a76ca438f874629d0d21ebac5"
          }
        },
        "ce72b35efd00414cabbfa4388ba8090a": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_9cca2d1724814b11ab93f931e8418b96",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "You: hey.\n"
                ]
              },
              {
                "output_type": "error",
                "ename": "IndexError",
                "evalue": "too many indices for tensor of dimension 2",
                "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                  "\u001b[0;32m<ipython-input-18-243ce4f21906>\u001b[0m in \u001b[0;36mon_send\u001b[0;34m(self, _)\u001b[0m\n\u001b[1;32m    112\u001b[0m            \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You: {user_input}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m                \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meliza_bot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Eliza: {response}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m<ipython-input-18-243ce4f21906>\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, input_text, max_length, min_length, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ELIZA:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_extra_spaces_and_line_breaks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m<ipython-input-18-243ce4f21906>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(self, encoded_input, max_length, min_length, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0mstopping_criteria_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStoppingCriteriaList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStoppingCriteriaSub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_token_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopping_criteria\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstopping_criteria_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
                ]
              }
            ]
          }
        },
        "3d07609887ff463db060510a81cc49e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b36e8e259ff94d18a488bcec5e93d755",
              "IPY_MODEL_408fe55e9f9a4f359e9481a42884b4e5"
            ],
            "layout": "IPY_MODEL_763946af178c423783fc35d73fe58486"
          }
        },
        "62cb2396d6ce443aa41ca5fbd85cfacf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_887fc128605f474386c838424aa9238a",
              "IPY_MODEL_0d04914b6c9d404bba304fbe44bcedfe"
            ],
            "layout": "IPY_MODEL_d21392be759b43a7b200f68c6953b51d"
          }
        },
        "233cd86a76ca438f874629d0d21ebac5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b36e8e259ff94d18a488bcec5e93d755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "You:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_38d993f7de38496ea8d3f31b1a4ba642",
            "placeholder": "Type your message here",
            "style": "IPY_MODEL_d12a1a3304ae4773b7565cf74dc6a3c5",
            "value": ""
          }
        },
        "408fe55e9f9a4f359e9481a42884b4e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Send",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_8bde152684f3422ebe31237230aa1dad",
            "style": "IPY_MODEL_095629da47434e2e90db3e347903e974",
            "tooltip": ""
          }
        },
        "763946af178c423783fc35d73fe58486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "887fc128605f474386c838424aa9238a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Clear",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ef68f1c9e57c4c4cbbae2086ac719ed6",
            "style": "IPY_MODEL_2b28353c770b4933b90bfbd0931c29ee",
            "tooltip": ""
          }
        },
        "0d04914b6c9d404bba304fbe44bcedfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Stop",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9de705f935134e8f90fcfb994841f0e7",
            "style": "IPY_MODEL_313b1cf1eb5044eda96788937563c836",
            "tooltip": ""
          }
        },
        "d21392be759b43a7b200f68c6953b51d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38d993f7de38496ea8d3f31b1a4ba642": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d12a1a3304ae4773b7565cf74dc6a3c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bde152684f3422ebe31237230aa1dad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095629da47434e2e90db3e347903e974": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "ef68f1c9e57c4c4cbbae2086ac719ed6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2b28353c770b4933b90bfbd0931c29ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9de705f935134e8f90fcfb994841f0e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "313b1cf1eb5044eda96788937563c836": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "9cca2d1724814b11ab93f931e8418b96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b99153eba5714eaaa0b372debef2a169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0414e8f390d645339e2b62d80d6b6c9a",
              "IPY_MODEL_5b53409259f14832af044996c267516d",
              "IPY_MODEL_4de5531a7abb474bb4cd1dc6b4c16f4a"
            ],
            "layout": "IPY_MODEL_d2ef367389f2429ba51e176f9d057016"
          }
        },
        "0414e8f390d645339e2b62d80d6b6c9a": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_03fb082b9bcc44f9a6242368a9064dd8",
            "msg_id": "",
            "outputs": []
          }
        },
        "5b53409259f14832af044996c267516d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_596d090d195141aab409498e7df6d84f",
              "IPY_MODEL_237710da57f244efbfa892bb031b260f"
            ],
            "layout": "IPY_MODEL_5316d15550fb445c9f87ae9776b94608"
          }
        },
        "4de5531a7abb474bb4cd1dc6b4c16f4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e108928cccbb4b90a8e0f4f5f5bfe069",
              "IPY_MODEL_cc1c16ef8b524f3b908dea2f701959ad"
            ],
            "layout": "IPY_MODEL_f11f39c88e234cb486ee84f6fa5d44c8"
          }
        },
        "d2ef367389f2429ba51e176f9d057016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "596d090d195141aab409498e7df6d84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "You:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_25d877a0026f4b0fbb33d296b01a036c",
            "placeholder": "Type your message here",
            "style": "IPY_MODEL_b46d5b794a2b47ba81e29bb904284614",
            "value": ""
          }
        },
        "237710da57f244efbfa892bb031b260f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Send",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_e6ab9f6d234f4eafa287b6e41a129a58",
            "style": "IPY_MODEL_4d02d6381fb34f188f6e6ea2442fef1b",
            "tooltip": ""
          }
        },
        "5316d15550fb445c9f87ae9776b94608": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e108928cccbb4b90a8e0f4f5f5bfe069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Clear",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_4ed4ab5eca6849c9bdf410f97f1cfa31",
            "style": "IPY_MODEL_9a36d922b97b4b2b8f86060e940a6783",
            "tooltip": ""
          }
        },
        "cc1c16ef8b524f3b908dea2f701959ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Stop",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a864f541f1b2450c8b64b1df60ed3ec1",
            "style": "IPY_MODEL_b97354f56bbb4ca5b34ae7f955f33f61",
            "tooltip": ""
          }
        },
        "f11f39c88e234cb486ee84f6fa5d44c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25d877a0026f4b0fbb33d296b01a036c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b46d5b794a2b47ba81e29bb904284614": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e6ab9f6d234f4eafa287b6e41a129a58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d02d6381fb34f188f6e6ea2442fef1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "4ed4ab5eca6849c9bdf410f97f1cfa31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a36d922b97b4b2b8f86060e940a6783": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "a864f541f1b2450c8b64b1df60ed3ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b97354f56bbb4ca5b34ae7f955f33f61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "03fb082b9bcc44f9a6242368a9064dd8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8f7c564f15f4625b9af3b837df2dab7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_745f0dfc29054c7c881c347d8c973858",
              "IPY_MODEL_fe587d2f2da04703b510419d1cd3e778",
              "IPY_MODEL_4a9c145c83384c9a88e6594a81ffd2d2"
            ],
            "layout": "IPY_MODEL_b00b8d9990f1472ab99f2e67db3cd1c4"
          }
        },
        "745f0dfc29054c7c881c347d8c973858": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_6d9feb89a21c4b44806b3cd9c6c125d9",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "You: hey nig\n"
                ]
              },
              {
                "output_type": "error",
                "ename": "IndexError",
                "evalue": "too many indices for tensor of dimension 2",
                "traceback": [
                  "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                  "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
                  "\u001b[0;32m<ipython-input-27-8e4856a3351c>\u001b[0m in \u001b[0;36mon_send\u001b[0;34m(self, _)\u001b[0m\n\u001b[1;32m    108\u001b[0m            \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"You: {user_input}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meliza_bot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Eliza: {response}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m<ipython-input-27-8e4856a3351c>\u001b[0m in \u001b[0;36mchat\u001b[0;34m(self, input_text, max_length, min_length, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ELIZA:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_extra_spaces_and_line_breaks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;32m<ipython-input-27-8e4856a3351c>\u001b[0m in \u001b[0;36mgenerate_response\u001b[0;34m(self, encoded_input, max_length, min_length, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mstopping_criteria_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStoppingCriteriaList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mStoppingCriteriaSub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstops\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_token_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m             \u001b[0moutput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'input_ids'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoded_input\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'attention_mask'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmin_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopping_criteria\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstopping_criteria_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m             \u001b[0mdecoded_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecoded_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
                  "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
                ]
              }
            ]
          }
        },
        "fe587d2f2da04703b510419d1cd3e778": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dd650e021ae5499eb82b00ff2640a4e8",
              "IPY_MODEL_28126ac8c8bb4794908d0c765cbc309c"
            ],
            "layout": "IPY_MODEL_dd232112b1274a36a7eba53c0db07b3b"
          }
        },
        "4a9c145c83384c9a88e6594a81ffd2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b02bb45c6d964a6aa43bf6e9fcde7d8f",
              "IPY_MODEL_8f54c7b338484b5d92d7071d89fcf459"
            ],
            "layout": "IPY_MODEL_87e692cd03d146c5bb679ce98320cd6a"
          }
        },
        "b00b8d9990f1472ab99f2e67db3cd1c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd650e021ae5499eb82b00ff2640a4e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "You:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_855a915e9d664104bccf87b0cab791d6",
            "placeholder": "Type your message here",
            "style": "IPY_MODEL_4d83ce12adc34c5593a68a98be20a5ed",
            "value": ""
          }
        },
        "28126ac8c8bb4794908d0c765cbc309c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Send",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_e0426331e33a462bb94194b9dba26e02",
            "style": "IPY_MODEL_c89bfb3408f041b18da4ee1536f2cdac",
            "tooltip": ""
          }
        },
        "dd232112b1274a36a7eba53c0db07b3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b02bb45c6d964a6aa43bf6e9fcde7d8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Clear",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_dd5a87741a434597b863bd4dc83fb576",
            "style": "IPY_MODEL_05638e4dd70f4f7399f6372e3842441b",
            "tooltip": ""
          }
        },
        "8f54c7b338484b5d92d7071d89fcf459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Stop",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_59a31ba5926244888dbc365e30d7a755",
            "style": "IPY_MODEL_26ab81f089a7498996ffc215c978223d",
            "tooltip": ""
          }
        },
        "87e692cd03d146c5bb679ce98320cd6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "855a915e9d664104bccf87b0cab791d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d83ce12adc34c5593a68a98be20a5ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0426331e33a462bb94194b9dba26e02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c89bfb3408f041b18da4ee1536f2cdac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "dd5a87741a434597b863bd4dc83fb576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05638e4dd70f4f7399f6372e3842441b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "59a31ba5926244888dbc365e30d7a755": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26ab81f089a7498996ffc215c978223d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6d9feb89a21c4b44806b3cd9c6c125d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sd6tiskTzPIp",
        "outputId": "8269aa0b-39d8-4b18-98e4-bcf65260339d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'eliza'...\n",
            "remote: Enumerating objects: 88433, done.\u001b[K\n",
            "remote: Counting objects: 100% (189/189), done.\u001b[K\n",
            "remote: Compressing objects: 100% (87/87), done.\u001b[K\n",
            "remote: Total 88433 (delta 165), reused 102 (delta 102), pack-reused 88244 (from 2)\u001b[K\n",
            "Receiving objects: 100% (88433/88433), 214.12 MiB | 16.37 MiB/s, done.\n",
            "Resolving deltas: 100% (56961/56961), done.\n",
            "Updating files: 100% (3557/3557), done.\n",
            "/content/eliza\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/elizaOS/eliza.git\n",
        "%cd eliza"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch transformers accelerate peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoFzdMv2zhZ1",
        "outputId": "24e53ac5-0f78-4d2f-d5b7-e7e208e30fff"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.2.1)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.11/dist-packages (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.10.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"USE_GPU\"] = \"True\""
      ],
      "metadata": {
        "id": "UrpBOIXo1RpD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/eliza/eliza_chat.py\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from utils.text_utils import remove_extra_spaces_and_line_breaks\n",
        "\n",
        "def load_model(model_name_or_path, accelerator, lora_weights=None):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16 if accelerator.device.type == \"cuda\" else torch.float32)\n",
        "    if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "            model.config.pad_token_id = model.config.eos_token_id\n",
        "    if lora_weights:\n",
        "        config = LoraConfig(\n",
        "            task_type=TaskType.CAUSAL_LM,\n",
        "            inference_mode=True,\n",
        "            r=8,\n",
        "            lora_alpha=32,\n",
        "            lora_dropout=0.05,\n",
        "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "        )\n",
        "\n",
        "        model = get_peft_model(model, config)\n",
        "        accelerator.print(\"Loading lora_weights\", lora_weights)\n",
        "        model.load_adapter(lora_weights)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "class StoppingCriteriaSub(StoppingCriteria):\n",
        "    def __init__(self, stops = [], encounters=1):\n",
        "        super().__init__()\n",
        "        self.stops = stops\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop in self.stops:\n",
        "            if torch.all((input_ids[-len(stop):] == stop)):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "class ElizaBot:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "        self.accelerator = Accelerator(cpu=not use_gpu)\n",
        "        self.device = self.accelerator.device\n",
        "        self.model, self.tokenizer = load_model(model_name, self.accelerator, lora_weights)\n",
        "        self.model = self.accelerator.prepare(self.model)\n",
        "        self.stop_words = [\"USER:\", \"ELIZA:\"]\n",
        "        self.stop_token_ids = []\n",
        "        for stop_word in self.stop_words:\n",
        "            encoded = self.tokenizer.encode(stop_word, add_special_tokens=False)\n",
        "            if len(encoded) > 0:\n",
        "                self.stop_token_ids.append(encoded)\n",
        "    def prepare_input(self, input_text):\n",
        "        prompt = f\"USER: {input_text}\\nELIZA:\"\n",
        "        encoded_input = self.tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\")\n",
        "        return encoded_input.to(self.device)\n",
        "    def generate_response(self, encoded_input, max_length=512, min_length=50, **kwargs):\n",
        "            stopping_criteria_list = StoppingCriteriaList([StoppingCriteriaSub(stops=self.stop_token_ids)])\n",
        "            with torch.no_grad():\n",
        "                output_ids = self.model.generate(encoded_input, max_length=max_length, min_length=min_length, stopping_criteria=stopping_criteria_list, **kwargs)\n",
        "                decoded_output = self.tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "            return decoded_output\n",
        "    def chat(self, input_text, max_length=512, min_length=50, **kwargs):\n",
        "        input_ids = self.prepare_input(input_text)\n",
        "        output = self.generate_response(input_ids, max_length, min_length, **kwargs)\n",
        "        output = output.split(\"ELIZA:\")[-1]\n",
        "        output = remove_extra_spaces_and_line_breaks(output)\n",
        "        return output\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Run the Eliza chatbot.')\n",
        "    parser.add_argument('--model', type=str, default=\"microsoft/DialoGPT-medium\", help='The name or path of the model to use.')\n",
        "    parser.add_argument('--lora', type=str, default=None, help='The path to the LORA adapter to use')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='Use GPU if available')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    eliza_bot = ElizaBot(args.model, lora_weights=args.lora, use_gpu=args.use_gpu)\n",
        "    print(\"Eliza is ready. Type 'exit' to end the chat.\")\n",
        "    while True:\n",
        "      user_input = input(\"You: \")\n",
        "      if user_input.lower() == \"exit\":\n",
        "          break\n",
        "      response = eliza_bot.chat(user_input)\n",
        "      print(\"Eliza:\", response)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lge-ovl-2MW5",
        "outputId": "0661dd46-f162-44f7-9b9e-573058eb1086"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/eliza/eliza_chat.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir /content/eliza/utils\n"
      ],
      "metadata": {
        "id": "IAmRzeJo41LM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/eliza/utils/text_utils.py\n",
        "import re\n",
        "\n",
        "def remove_extra_spaces_and_line_breaks(text):\n",
        "    \"\"\"Removes extra spaces and line breaks from the given text.\"\"\"\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.replace('\\n', ' ').strip()\n",
        "    return text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-Hl65Rv45N-",
        "outputId": "f13dc0fc-d56e-4c90-9d43-002dc8c67a49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing /content/eliza/utils/text_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/eliza/eliza_chat.py --model \"microsoft/DialoGPT-medium\" --use_gpu True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NpybL0B949Ry",
        "outputId": "ae893074-9498-4339-c750-56f6099101f3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-03 03:39:13.174839: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1738553953.200394    7320 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1738553953.208503    7320 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-03 03:39:13.235192: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "tokenizer_config.json: 100% 614/614 [00:00<00:00, 2.50MB/s]\n",
            "vocab.json: 100% 1.04M/1.04M [00:00<00:00, 10.7MB/s]\n",
            "merges.txt: 100% 456k/456k [00:00<00:00, 5.54MB/s]\n",
            "config.json: 100% 642/642 [00:00<00:00, 3.65MB/s]\n",
            "pytorch_model.bin: 100% 863M/863M [00:10<00:00, 81.3MB/s]\n",
            "generation_config.json: 100% 124/124 [00:00<00:00, 622kB/s]\n",
            "Eliza is ready. Type 'exit' to end the chat.\n",
            "You: hey what are you running under the hood.. .who are you?\n",
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/eliza/eliza_chat.py\", line 86, in <module>\n",
            "    response = eliza_bot.chat(user_input)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/eliza/eliza_chat.py\", line 67, in chat\n",
            "    output = self.generate_response(input_ids, max_length, min_length, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/eliza/eliza_chat.py\", line 62, in generate_response\n",
            "    output_ids = self.model.generate(encoded_input, max_length=max_length, min_length=min_length, stopping_criteria=stopping_criteria_list, **kwargs)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 2252, in generate\n",
            "    result = self._sample(\n",
            "             ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 3310, in _sample\n",
            "    unfinished_sequences = unfinished_sequences & ~stopping_criteria(input_ids, scores)\n",
            "                                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/stopping_criteria.py\", line 496, in __call__\n",
            "    is_done = is_done | criteria(input_ids, scores, **kwargs)\n",
            "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/eliza/eliza_chat.py\", line 39, in __call__\n",
            "    if torch.all((input_ids[-len(stop):] == stop)):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "TypeError: all() received an invalid combination of arguments - got (bool), but expected one of:\n",
            " * (Tensor input, *, Tensor out = None)\n",
            " * (Tensor input, tuple of ints dim = None, bool keepdim = False, *, Tensor out = None)\n",
            " * (Tensor input, int dim, bool keepdim = False, *, Tensor out = None)\n",
            " * (Tensor input, name dim, bool keepdim = False, *, Tensor out = None)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Run the Eliza chatbot.')\n",
        "    parser.add_argument('--model', type=str, default=\"microsoft/DialoGPT-medium\", help='The name or path of the model to use.')\n",
        "    parser.add_argument('--lora', type=str, default=None, help='The path to the LORA adapter to use')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='Use GPU if available')\n",
        "    args = parser.parse_args(args=[]) # The change is right here.\n",
        "    eliza_interface = ElizaInterface(args.model, lora_weights=args.lora, use_gpu=args.use_gpu)\n",
        "    eliza_interface.display()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701,
          "referenced_widgets": [
            "ff298b672cef4caab82cdd3f177111eb",
            "703481bcae4e4cb497d10cb3df94be31",
            "0bc7a995aa234f15a1b02eb42a5bcc07",
            "e4c982bb385e4cfd82a48890d7201f1c",
            "14c2c706e43648c6ac09b2bde6913e35",
            "b5fda6af691c4897a396d057ecb0d317",
            "e542969977f64dbeb23823e76099e04e",
            "b242d049bec14e6899400d24de57c730",
            "025f4038434e4763b247099a3e576503",
            "6c990985d0aa47f191c0c7c2322d6fab",
            "5285f975274943b2bb63d2a1c36f543b",
            "2416415299a24657b01fbeb0c2782d5c",
            "37233b15db36446d9618e1bded185a04",
            "4d193158f2f447b0b998965aa65ae1d2",
            "e51eb9f2ee544260ac643d5afbeab6b4",
            "09b1bfe99b3144c5a30bd2031500b70e",
            "5e9630cb610b453680b4a9d0537e8327",
            "7bbcdff024c14be18871b72b2be2220e",
            "d2ac2a22947e46b4b5d9173829d9d578",
            "350f0d5f6a5a4137b20583cee0162ebb"
          ]
        },
        "id": "gPOPEmwu6LbV",
        "outputId": "6dfe6939-3f05-4e7b-b508-f23f0f0e5d36"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Output(), HBox(children=(Text(value='', description='You:', placeholder='Type your message here…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff298b672cef4caab82cdd3f177111eb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from utils.text_utils import remove_extra_spaces_and_line_breaks\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from IPython.display import Javascript\n",
        "import asyncio\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "def load_model(model_name_or_path, accelerator, lora_weights=None):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16 if accelerator.device.type == \"cuda\" else torch.float32)\n",
        "    if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "            model.config.pad_token_id = model.config.eos_token_id\n",
        "    if lora_weights:\n",
        "        config = LoraConfig(\n",
        "            task_type=TaskType.CAUSAL_LM,\n",
        "            inference_mode=True,\n",
        "            r=8,\n",
        "            lora_alpha=32,\n",
        "            lora_dropout=0.05,\n",
        "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "        )\n",
        "\n",
        "        model = get_peft_model(model, config)\n",
        "        accelerator.print(\"Loading lora_weights\", lora_weights)\n",
        "        model.load_adapter(lora_weights)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "class StoppingCriteriaSub(StoppingCriteria):\n",
        "    def __init__(self, stops = [], encounters=1):\n",
        "        super().__init__()\n",
        "        self.stops = stops\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop in self.stops:\n",
        "            if torch.all((input_ids[-len(stop):] == stop)):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "class ElizaBot:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "        self.accelerator = Accelerator(cpu=not use_gpu)\n",
        "        self.device = self.accelerator.device\n",
        "        self.model, self.tokenizer = load_model(model_name, self.accelerator, lora_weights)\n",
        "        self.model = self.accelerator.prepare(self.model)\n",
        "        self.stop_words = [\"USER:\", \"ELIZA:\"]\n",
        "        self.stop_token_ids = []\n",
        "        for stop_word in self.stop_words:\n",
        "            encoded = self.tokenizer.encode(stop_word, add_special_tokens=False)\n",
        "            if len(encoded) > 0:\n",
        "                self.stop_token_ids.append(encoded)\n",
        "        self.chat_history = []  # Initialize chat history\n",
        "\n",
        "    def prepare_input(self, input_text):\n",
        "         prompt = \"\\n\".join(self.chat_history + [f\"USER: {input_text}\", \"ELIZA:\"])\n",
        "         encoded_input = self.tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\")\n",
        "         return encoded_input.to(self.device)\n",
        "\n",
        "    def generate_response(self, encoded_input, max_length=512, min_length=50, **kwargs):\n",
        "            stopping_criteria_list = StoppingCriteriaList([StoppingCriteriaSub(stops=self.stop_token_ids)])\n",
        "            with torch.no_grad():\n",
        "                output_ids = self.model.generate(encoded_input, max_length=max_length, min_length=min_length, stopping_criteria=stopping_criteria_list, **kwargs)\n",
        "                decoded_output = self.tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "            return decoded_output\n",
        "\n",
        "    def chat(self, input_text, max_length=512, min_length=50, **kwargs):\n",
        "        input_ids = self.prepare_input(input_text)\n",
        "        output = self.generate_response(input_ids, max_length, min_length, **kwargs)\n",
        "        output = output.split(\"ELIZA:\")[-1]\n",
        "        output = remove_extra_spaces_and_line_breaks(output)\n",
        "        self.chat_history.append(f\"USER: {input_text}\")\n",
        "        self.chat_history.append(f\"ELIZA: {output}\")\n",
        "\n",
        "        return output\n",
        "\n",
        "class ElizaInterface:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "         self.hf_token = userdata.get('HF_TOKEN')\n",
        "         if self.hf_token:\n",
        "            login(self.hf_token)\n",
        "            print(\"Successfully logged in to Hugging Face!\")\n",
        "         else:\n",
        "           print(\"Token is not set. Please save the token first.\")\n",
        "         self.eliza_bot = ElizaBot(model_name, lora_weights, use_gpu)\n",
        "         self.chat_output = widgets.Output()\n",
        "         self.input_text = widgets.Text(description=\"You:\", placeholder=\"Type your message here\")\n",
        "         self.send_button = widgets.Button(description=\"Send\")\n",
        "         self.clear_button = widgets.Button(description=\"Clear\")\n",
        "         self.stop_button = widgets.Button(description=\"Stop\")\n",
        "         self.is_running = True\n",
        "         self.send_button.on_click(self.on_send)\n",
        "         self.clear_button.on_click(self.on_clear)\n",
        "         self.stop_button.on_click(self.on_stop)\n",
        "         self.chat_display = widgets.VBox([self.chat_output,widgets.HBox([self.input_text, self.send_button]), widgets.HBox([self.clear_button, self.stop_button])])\n",
        "    def on_send(self, _):\n",
        "        if not self.is_running:\n",
        "           return\n",
        "        user_input = self.input_text.value\n",
        "        self.input_text.value = ''  # Clear the input text\n",
        "        if user_input:\n",
        "           with self.chat_output:\n",
        "               print(f\"You: {user_input}\")\n",
        "               response = self.eliza_bot.chat(user_input)\n",
        "               print(f\"Eliza: {response}\")\n",
        "\n",
        "    def on_clear(self, _):\n",
        "        self.eliza_bot.chat_history = []\n",
        "        with self.chat_output:\n",
        "           clear_output()\n",
        "\n",
        "    def on_stop(self, _):\n",
        "        self.is_running = False\n",
        "        self.send_button.disabled = True\n",
        "        with self.chat_output:\n",
        "          print(\"Eliza is not listening, restart by re-running the whole script.\")\n",
        "\n",
        "    def display(self):\n",
        "        display(self.chat_display)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Run the Eliza chatbot.')\n",
        "    parser.add_argument('--model', type=str, default=\"microsoft/DialoGPT-medium\", help='The name or path of the model to use.')\n",
        "    parser.add_argument('--lora', type=str, default=None, help='The path to the LORA adapter to use')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='Use GPU if available')\n",
        "    args = parser.parse_args(args=[])\n",
        "    eliza_interface = ElizaInterface(args.model, lora_weights=args.lora, use_gpu=args.use_gpu)\n",
        "    eliza_interface.display()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 594,
          "referenced_widgets": [
            "ac757a68aa0a405f89a8bce545838ee2",
            "85340d8b00ea44d1859f2da7b6aebbd9",
            "113032abc9cf4c3b8ea276a0f04b2d45",
            "544ecbbebb3d48afb97705621909169f",
            "15f02b54646b4ab9b5b091290bb5e6aa",
            "b0e3e11f9e694ac2b7e0f5f9f30dc29d",
            "eb764e8934d2422a8d50315463af8505",
            "ea625e433a2e423f918a14087ce4fb70",
            "a7f3ed5d6f194ab6b7ee6c2d65da55d3",
            "186e6dc580144ce6b58ce2e45d92b904",
            "675b57dd2a54441f8880398976d20a1f",
            "b71b74f324e6409c809e172498d07c62",
            "fdb4b367466e45569fd4291f36e8cc30",
            "075933477c8c4e27abc82c2a03aeec13",
            "d3ec064de1fb479bae5bd2af6699cb79",
            "8801940601db417cb205b60e30fa5f54",
            "edfe37c319dd477f808c8fb6ea5b2923",
            "370f12f55a784956ab7c9d900df63035",
            "c46aa4dba8924f84adf3485b0ba6bc3d",
            "d35999a44db14c2fae7c1b6a665484f8"
          ]
        },
        "id": "KPWYiODj9vtS",
        "outputId": "49e2ee62-1c99-4ece-824f-e53bed7bf138"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully logged in to Hugging Face!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Output(), HBox(children=(Text(value='', description='You:', placeholder='Type your message here…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ac757a68aa0a405f89a8bce545838ee2"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class StoppingCriteriaSub(StoppingCriteria):\n",
        "    def __init__(self, stops = [], encounters=1):\n",
        "        super().__init__()\n",
        "        self.stops = stops\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop in self.stops:\n",
        "            stop_tensor = torch.tensor(stop, device=input_ids.device)\n",
        "            if torch.all(input_ids[-len(stop):] == stop_tensor):\n",
        "                return True\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "pGDydKQW-zPv"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_input(self, input_text):\n",
        "    prompt = \"\\n\".join(self.chat_history + [f\"USER: {input_text}\", \"ELIZA:\"])\n",
        "    encoded_input = self.tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\", return_attention_mask=True)\n",
        "    return encoded_input.to(self.device)\n",
        "\n",
        "def generate_response(self, encoded_input, max_length=512, min_length=50, **kwargs):\n",
        "    stopping_criteria_list = StoppingCriteriaList([StoppingCriteriaSub(stops=self.stop_token_ids)])\n",
        "    with torch.no_grad():\n",
        "        output_ids = self.model.generate(input_ids=encoded_input['input_ids'], attention_mask=encoded_input['attention_mask'], max_length=max_length, min_length=min_length, stopping_criteria=stopping_criteria_list, **kwargs)\n",
        "        decoded_output = self.tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "    return decoded_output\n"
      ],
      "metadata": {
        "id": "ws8tUl0x-4fR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from utils.text_utils import remove_extra_spaces_and_line_breaks\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from IPython.display import Javascript\n",
        "import asyncio\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "def load_model(model_name_or_path, accelerator, lora_weights=None):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16 if accelerator.device.type == \"cuda\" else torch.float32)\n",
        "    if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "            model.config.pad_token_id = model.config.eos_token_id\n",
        "    if lora_weights:\n",
        "        config = LoraConfig(\n",
        "            task_type=TaskType.CAUSAL_LM,\n",
        "            inference_mode=True,\n",
        "            r=8,\n",
        "            lora_alpha=32,\n",
        "            lora_dropout=0.05,\n",
        "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "        )\n",
        "\n",
        "        model = get_peft_model(model, config)\n",
        "        accelerator.print(\"Loading lora_weights\", lora_weights)\n",
        "        model.load_adapter(lora_weights)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "class StoppingCriteriaSub(StoppingCriteria):\n",
        "    def __init__(self, stops = [], encounters=1):\n",
        "        super().__init__()\n",
        "        self.stops = stops\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop in self.stops:\n",
        "            stop_tensor = torch.tensor(stop, device=input_ids.device)\n",
        "            if torch.all(input_ids[-len(stop):] == stop_tensor):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "class ElizaBot:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "        self.accelerator = Accelerator(cpu=not use_gpu)\n",
        "        self.device = self.accelerator.device\n",
        "        self.model, self.tokenizer = load_model(model_name, self.accelerator, lora_weights)\n",
        "        self.model = self.accelerator.prepare(self.model)\n",
        "        self.stop_words = [\"USER:\", \"ELIZA:\"]\n",
        "        self.stop_token_ids = []\n",
        "        for stop_word in self.stop_words:\n",
        "            encoded = self.tokenizer.encode(stop_word, add_special_tokens=False)\n",
        "            if len(encoded) > 0:\n",
        "                self.stop_token_ids.append(encoded)\n",
        "        self.chat_history = []  # Initialize chat history\n",
        "\n",
        "    def prepare_input(self, input_text):\n",
        "        prompt = \"\\n\".join(self.chat_history + [f\"USER: {input_text}\", \"ELIZA:\"])\n",
        "        encoded_input = self.tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\", return_attention_mask=True)\n",
        "        return encoded_input.to(self.device)\n",
        "\n",
        "    def generate_response(self, encoded_input, max_length=512, min_length=50, **kwargs):\n",
        "        stopping_criteria_list = StoppingCriteriaList([StoppingCriteriaSub(stops=self.stop_token_ids)])\n",
        "        with torch.no_grad():\n",
        "            output_ids = self.model.generate(input_ids=encoded_input['input_ids'], attention_mask=encoded_input['attention_mask'], max_length=max_length, min_length=min_length, stopping_criteria=stopping_criteria_list, **kwargs)\n",
        "            decoded_output = self.tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "        return decoded_output\n",
        "\n",
        "    def chat(self, input_text, max_length=512, min_length=50, **kwargs):\n",
        "        input_ids = self.prepare_input(input_text)\n",
        "        output = self.generate_response(input_ids, max_length, min_length, **kwargs)\n",
        "        output = output.split(\"ELIZA:\")[-1]\n",
        "        output = remove_extra_spaces_and_line_breaks(output)\n",
        "        self.chat_history.append(f\"USER: {input_text}\")\n",
        "        self.chat_history.append(f\"ELIZA: {output}\")\n",
        "\n",
        "        return output\n",
        "\n",
        "class ElizaInterface:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "         self.hf_token = userdata.get('HF_TOKEN')\n",
        "         if self.hf_token:\n",
        "            login(self.hf_token)\n",
        "            print(\"Successfully logged in to Hugging Face!\")\n",
        "         else:\n",
        "           print(\"Token is not set. Please save the token first.\")\n",
        "         self.eliza_bot = ElizaBot(model_name, lora_weights, use_gpu)\n",
        "         self.chat_output = widgets.Output()\n",
        "         self.input_text = widgets.Text(description=\"You:\", placeholder=\"Type your message here\")\n",
        "         self.send_button = widgets.Button(description=\"Send\")\n",
        "         self.clear_button = widgets.Button(description=\"Clear\")\n",
        "         self.stop_button = widgets.Button(description=\"Stop\")\n",
        "         self.is_running = True\n",
        "         self.send_button.on_click(self.on_send)\n",
        "         self.clear_button.on_click(self.on_clear)\n",
        "         self.stop_button.on_click(self.on_stop)\n",
        "         self.chat_display = widgets.VBox([self.chat_output,widgets.HBox([self.input_text, self.send_button]), widgets.HBox([self.clear_button, self.stop_button])])\n",
        "    def on_send(self, _):\n",
        "        if not self.is_running:\n",
        "           return\n",
        "        user_input = self.input_text.value\n",
        "        self.input_text.value = ''  # Clear the input text\n",
        "        if user_input:\n",
        "           with self.chat_output:\n",
        "               print(f\"You: {user_input}\")\n",
        "               response = self.eliza_bot.chat(user_input)\n",
        "               print(f\"Eliza: {response}\")\n",
        "\n",
        "    def on_clear(self, _):\n",
        "        self.eliza_bot.chat_history = []\n",
        "        with self.chat_output:\n",
        "           clear_output()\n",
        "\n",
        "    def on_stop(self, _):\n",
        "        self.is_running = False\n",
        "        self.send_button.disabled = True\n",
        "        with self.chat_output:\n",
        "          print(\"Eliza is not listening, restart by re-running the whole script.\")\n",
        "\n",
        "    def display(self):\n",
        "        display(self.chat_display)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Run the Eliza chatbot.')\n",
        "    parser.add_argument('--model', type=str, default=\"microsoft/DialoGPT-medium\", help='The name or path of the model to use.')\n",
        "    parser.add_argument('--lora', type=str, default=None, help='The path to the LORA adapter to use')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='Use GPU if available')\n",
        "    args = parser.parse_args(args=[])\n",
        "    eliza_interface = ElizaInterface(args.model, lora_weights=args.lora, use_gpu=args.use_gpu)\n",
        "    eliza_interface.display()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524,
          "referenced_widgets": [
            "ab1ee86faf1742e28abce194da96e6bb",
            "ce72b35efd00414cabbfa4388ba8090a",
            "3d07609887ff463db060510a81cc49e1",
            "62cb2396d6ce443aa41ca5fbd85cfacf",
            "233cd86a76ca438f874629d0d21ebac5",
            "b36e8e259ff94d18a488bcec5e93d755",
            "408fe55e9f9a4f359e9481a42884b4e5",
            "763946af178c423783fc35d73fe58486",
            "887fc128605f474386c838424aa9238a",
            "0d04914b6c9d404bba304fbe44bcedfe",
            "d21392be759b43a7b200f68c6953b51d",
            "38d993f7de38496ea8d3f31b1a4ba642",
            "d12a1a3304ae4773b7565cf74dc6a3c5",
            "8bde152684f3422ebe31237230aa1dad",
            "095629da47434e2e90db3e347903e974",
            "ef68f1c9e57c4c4cbbae2086ac719ed6",
            "2b28353c770b4933b90bfbd0931c29ee",
            "9de705f935134e8f90fcfb994841f0e7",
            "313b1cf1eb5044eda96788937563c836",
            "9cca2d1724814b11ab93f931e8418b96"
          ]
        },
        "id": "49veH1ij-8Rj",
        "outputId": "b2fb9793-6507-4d97-f0ec-370bba54d468"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully logged in to Hugging Face!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Output(), HBox(children=(Text(value='', description='You:', placeholder='Type your message here…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ab1ee86faf1742e28abce194da96e6bb"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/eliza/eliza_chat.py\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from utils.text_utils import remove_extra_spaces_and_line_breaks\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from IPython.display import Javascript\n",
        "import asyncio\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "def load_model(model_name_or_path, accelerator, lora_weights=None):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16 if accelerator.device.type == \"cuda\" else torch.float32)\n",
        "    if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "            model.config.pad_token_id = model.config.eos_token_id\n",
        "    if lora_weights:\n",
        "        config = LoraConfig(\n",
        "            task_type=TaskType.CAUSAL_LM,\n",
        "            inference_mode=True,\n",
        "            r=8,\n",
        "            lora_alpha=32,\n",
        "            lora_dropout=0.05,\n",
        "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "        )\n",
        "\n",
        "        model = get_peft_model(model, config)\n",
        "        accelerator.print(\"Loading lora_weights\", lora_weights)\n",
        "        model.load_adapter(lora_weights)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "class StoppingCriteriaSub(StoppingCriteria):\n",
        "    def __init__(self, stops = [], encounters=1):\n",
        "        super().__init__()\n",
        "        self.stops = stops\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop in self.stops:\n",
        "            stop_tensor = torch.tensor(stop, device=input_ids.device)\n",
        "            if torch.all(input_ids[-len(stop):] == stop_tensor):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "class ElizaBot:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "        self.accelerator = Accelerator(cpu=not use_gpu)\n",
        "        self.device = self.accelerator.device\n",
        "        self.model, self.tokenizer = load_model(model_name, self.accelerator, lora_weights)\n",
        "        self.model = self.accelerator.prepare(self.model)\n",
        "        self.stop_words = [\"USER:\", \"ELIZA:\"]\n",
        "        self.stop_token_ids = []\n",
        "        for stop_word in self.stop_words:\n",
        "            encoded = self.tokenizer.encode(stop_word, add_special_tokens=False)\n",
        "            if len(encoded) > 0:\n",
        "                self.stop_token_ids.append(encoded)\n",
        "        self.chat_history = []  # Initialize chat history\n",
        "\n",
        "    def prepare_input(self, input_text):\n",
        "        prompt = \"\\n\".join(self.chat_history + [f\"USER: {input_text}\", \"ELIZA:\"])\n",
        "        encoded_input = self.tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\", return_attention_mask=True)\n",
        "        return encoded_input.to(self.device)\n",
        "\n",
        "    def generate_response(self, encoded_input, max_length=512, min_length=50, **kwargs):\n",
        "        stopping_criteria_list = StoppingCriteriaList([StoppingCriteriaSub(stops=self.stop_token_ids)])\n",
        "        with torch.no_grad():\n",
        "            output_ids = self.model.generate(input_ids=encoded_input['input_ids'], attention_mask=encoded_input['attention_mask'], max_length=max_length, min_length=min_length, stopping_criteria=stopping_criteria_list, **kwargs)\n",
        "            decoded_output = self.tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "        return decoded_output\n",
        "\n",
        "    def chat(self, input_text, max_length=512, min_length=50, **kwargs):\n",
        "        input_ids = self.prepare_input(input_text)\n",
        "        output = self.generate_response(input_ids, max_length, min_length, **kwargs)\n",
        "        output = output.split(\"ELIZA:\")[-1]\n",
        "        output = remove_extra_spaces_and_line_breaks(output)\n",
        "        self.chat_history.append(f\"USER: {input_text}\")\n",
        "        self.chat_history.append(f\"ELIZA: {output}\")\n",
        "\n",
        "        return output\n",
        "\n",
        "class ElizaInterface:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "         self.hf_token = userdata.get('HF_TOKEN')\n",
        "         if self.hf_token:\n",
        "            login(self.hf_token)\n",
        "            print(\"Successfully logged in to Hugging Face!\")\n",
        "         else:\n",
        "           print(\"Token is not set. Please save the token first.\")\n",
        "         self.eliza_bot = ElizaBot(model_name, lora_weights, use_gpu)\n",
        "         self.chat_output = widgets.Output()\n",
        "         self.input_text = widgets.Text(description=\"You:\", placeholder=\"Type your message here\")\n",
        "         self.send_button = widgets.Button(description=\"Send\")\n",
        "         self.clear_button = widgets.Button(description=\"Clear\")\n",
        "         self.stop_button = widgets.Button(description=\"Stop\")\n",
        "         self.is_running = True\n",
        "         self.send_button.on_click(self.on_send)\n",
        "         self.clear_button.on_click(self.on_clear)\n",
        "         self.stop_button.on_click(self.on_stop)\n",
        "         self.chat_display = widgets.VBox([self.chat_output,widgets.HBox([self.input_text, self.send_button]), widgets.HBox([self.clear_button, self.stop_button])])\n",
        "    def on_send(self, _):\n",
        "        if not self.is_running:\n",
        "           return\n",
        "        user_input = self.input_text.value\n",
        "        self.input_text.value = ''  # Clear the input text\n",
        "        if user_input:\n",
        "           with self.chat_output:\n",
        "               print(f\"You: {user_input}\")\n",
        "               response = self.eliza_bot.chat(user_input)\n",
        "               print(f\"Eliza: {response}\")\n",
        "\n",
        "    def on_clear(self, _):\n",
        "        self.eliza_bot.chat_history = []\n",
        "        with self.chat_output:\n",
        "           clear_output()\n",
        "\n",
        "    def on_stop(self, _):\n",
        "        self.is_running = False\n",
        "        self.send_button.disabled = True\n",
        "        with self.chat_output:\n",
        "          print(\"Eliza is not listening, restart by re-running the whole script.\")\n",
        "\n",
        "    def display(self):\n",
        "        display(self.chat_display)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Run the Eliza chatbot.')\n",
        "    parser.add_argument('--model', type=str, default=\"microsoft/DialoGPT-medium\", help='The name or path of the model to use.')\n",
        "    parser.add_argument('--lora', type=str, default=None, help='The path to the LORA adapter to use')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='Use GPU if available')\n",
        "    args = parser.parse_args(args=[])\n",
        "    eliza_interface = ElizaInterface(args.model, lora_weights=args.lora, use_gpu=args.use_gpu)\n",
        "    eliza_interface.display()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2AtVzH8_MpY",
        "outputId": "5cf653be-0e29-42ae-f4e1-69d66e843b59"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/eliza/eliza_chat.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/eliza/eliza_chat.py --model \"microsoft/DialoGPT-medium\" --use_gpu True\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnqRcW4B_S56",
        "outputId": "256032ca-e3fd-4c39-ffb6-6e3762726922"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-03 04:06:56.296540: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1738555616.323053   13969 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1738555616.330930   13969 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/eliza/eliza_chat.py\", line 138, in <module>\n",
            "    eliza_interface = ElizaInterface(args.model, lora_weights=args.lora, use_gpu=args.use_gpu)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/content/eliza/eliza_chat.py\", line 89, in __init__\n",
            "    self.hf_token = userdata.get('HF_TOKEN')\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\", line 62, in get\n",
            "    resp = _message.blocking_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\", line 173, in blocking_request\n",
            "    request_id = send_request(\n",
            "                 ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\", line 117, in send_request\n",
            "    instance = ipython.get_kernelapp()\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_ipython.py\", line 28, in get_kernelapp\n",
            "    return get_ipython().kernel.parent\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'kernel'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ElizaInterface:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "         self.eliza_bot = ElizaBot(model_name, lora_weights, use_gpu)\n",
        "         self.chat_output = widgets.Output()\n",
        "         self.input_text = widgets.Text(description=\"You:\", placeholder=\"Type your message here\")\n",
        "         self.send_button = widgets.Button(description=\"Send\")\n",
        "         self.clear_button = widgets.Button(description=\"Clear\")\n",
        "         self.stop_button = widgets.Button(description=\"Stop\")\n",
        "         self.is_running = True\n",
        "         self.send_button.on_click(self.on_send)\n",
        "         self.clear_button.on_click(self.on_clear)\n",
        "         self.stop_button.on_click(self.on_stop)\n",
        "         self.chat_display = widgets.VBox([self.chat_output,widgets.HBox([self.input_text, self.send_button]), widgets.HBox([self.clear_button, self.stop_button])])\n",
        "    def on_send(self, _):\n",
        "        if not self.is_running:\n",
        "           return\n",
        "        user_input = self.input_text.value\n",
        "        self.input_text.value = ''  # Clear the input text\n",
        "        if user_input:\n",
        "           with self.chat_output:\n",
        "               print(f\"You: {user_input}\")\n",
        "               response = self.eliza_bot.chat(user_input)\n",
        "               print(f\"Eliza: {response}\")\n",
        "\n",
        "    def on_clear(self, _):\n",
        "        self.eliza_bot.chat_history = []\n",
        "        with self.chat_output:\n",
        "           clear_output()\n",
        "\n",
        "    def on_stop(self, _):\n",
        "        self.is_running = False\n",
        "        self.send_button.disabled = True\n",
        "        with self.chat_output:\n",
        "          print(\"Eliza is not listening, restart by re-running the whole script.\")\n",
        "\n",
        "    def display(self):\n",
        "        self.hf_token = userdata.get('HF_TOKEN')\n",
        "        if self.hf_token:\n",
        "          login(self.hf_token)\n",
        "          print(\"Successfully logged in to Hugging Face!\")\n",
        "        else:\n",
        "           print(\"Token is not set. Please save the token first.\")\n",
        "        display(self.chat_display)\n"
      ],
      "metadata": {
        "id": "kvkMIeTW_tLM"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from utils.text_utils import remove_extra_spaces_and_line_breaks\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from IPython.display import Javascript\n",
        "import asyncio\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "def load_model(model_name_or_path, accelerator, lora_weights=None):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16 if accelerator.device.type == \"cuda\" else torch.float32)\n",
        "    if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "            model.config.pad_token_id = model.config.eos_token_id\n",
        "    if lora_weights:\n",
        "        config = LoraConfig(\n",
        "            task_type=TaskType.CAUSAL_LM,\n",
        "            inference_mode=True,\n",
        "            r=8,\n",
        "            lora_alpha=32,\n",
        "            lora_dropout=0.05,\n",
        "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "        )\n",
        "\n",
        "        model = get_peft_model(model, config)\n",
        "        accelerator.print(\"Loading lora_weights\", lora_weights)\n",
        "        model.load_adapter(lora_weights)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "class StoppingCriteriaSub(StoppingCriteria):\n",
        "    def __init__(self, stops = [], encounters=1):\n",
        "        super().__init__()\n",
        "        self.stops = stops\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop in self.stops:\n",
        "            stop_tensor = torch.tensor(stop, device=input_ids.device)\n",
        "            if torch.all(input_ids[-len(stop):] == stop_tensor):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "class ElizaBot:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "        self.accelerator = Accelerator(cpu=not use_gpu)\n",
        "        self.device = self.accelerator.device\n",
        "        self.model, self.tokenizer = load_model(model_name, self.accelerator, lora_weights)\n",
        "        self.model = self.accelerator.prepare(self.model)\n",
        "        self.stop_words = [\"USER:\", \"ELIZA:\"]\n",
        "        self.stop_token_ids = []\n",
        "        for stop_word in self.stop_words:\n",
        "            encoded = self.tokenizer.encode(stop_word, add_special_tokens=False)\n",
        "            if len(encoded) > 0:\n",
        "                self.stop_token_ids.append(encoded)\n",
        "        self.chat_history = []  # Initialize chat history\n",
        "\n",
        "    def prepare_input(self, input_text):\n",
        "        prompt = \"\\n\".join(self.chat_history + [f\"USER: {input_text}\", \"ELIZA:\"])\n",
        "        encoded_input = self.tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\", return_attention_mask=True)\n",
        "        return encoded_input.to(self.device)\n",
        "\n",
        "    def generate_response(self, encoded_input, max_length=512, min_length=50, **kwargs):\n",
        "        stopping_criteria_list = StoppingCriteriaList([StoppingCriteriaSub(stops=self.stop_token_ids)])\n",
        "        with torch.no_grad():\n",
        "            output_ids = self.model.generate(input_ids=encoded_input['input_ids'], attention_mask=encoded_input['attention_mask'], max_length=max_length, min_length=min_length, stopping_criteria=stopping_criteria_list, **kwargs)\n",
        "            decoded_output = self.tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "        return decoded_output\n",
        "\n",
        "    def chat(self, input_text, max_length=512, min_length=50, **kwargs):\n",
        "        input_ids = self.prepare_input(input_text)\n",
        "        output = self.generate_response(input_ids, max_length, min_length, **kwargs)\n",
        "        output = output.split(\"ELIZA:\")[-1]\n",
        "        output = remove_extra_spaces_and_line_breaks(output)\n",
        "        self.chat_history.append(f\"USER: {input_text}\")\n",
        "        self.chat_history.append(f\"ELIZA: {output}\")\n",
        "\n",
        "        return output\n",
        "\n",
        "class ElizaInterface:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "         self.eliza_bot = ElizaBot(model_name, lora_weights, use_gpu)\n",
        "         self.chat_output = widgets.Output()\n",
        "         self.input_text = widgets.Text(description=\"You:\", placeholder=\"Type your message here\")\n",
        "         self.send_button = widgets.Button(description=\"Send\")\n",
        "         self.clear_button = widgets.Button(description=\"Clear\")\n",
        "         self.stop_button = widgets.Button(description=\"Stop\")\n",
        "         self.is_running = True\n",
        "         self.send_button.on_click(self.on_send)\n",
        "         self.clear_button.on_click(self.on_clear)\n",
        "         self.stop_button.on_click(self.on_stop)\n",
        "         self.chat_display = widgets.VBox([self.chat_output,widgets.HBox([self.input_text, self.send_button]), widgets.HBox([self.clear_button, self.stop_button])])\n",
        "    def on_send(self, _):\n",
        "        if not self.is_running:\n",
        "           return\n",
        "        user_input = self.input_text.value\n",
        "        self.input_text.value = ''  # Clear the input text\n",
        "        if user_input:\n",
        "           with self.chat_output:\n",
        "               print(f\"You: {user_input}\")\n",
        "               response = self.eliza_bot.chat(user_input)\n",
        "               print(f\"Eliza: {response}\")\n",
        "\n",
        "    def on_clear(self, _):\n",
        "        self.eliza_bot.chat_history = []\n",
        "        with self.chat_output:\n",
        "           clear_output()\n",
        "\n",
        "    def on_stop(self, _):\n",
        "        self.is_running = False\n",
        "        self.send_button.disabled = True\n",
        "        with self.chat_output:\n",
        "          print(\"Eliza is not listening, restart by re-running the whole script.\")\n",
        "\n",
        "    def display(self):\n",
        "        self.hf_token = userdata.get('HF_TOKEN')\n",
        "        if self.hf_token:\n",
        "          login(self.hf_token)\n",
        "          print(\"Successfully logged in to Hugging Face!\")\n",
        "        else:\n",
        "           print(\"Token is not set. Please save the token first.\")\n",
        "        display(self.chat_display)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Run the Eliza chatbot.')\n",
        "    parser.add_argument('--model', type=str, default=\"microsoft/DialoGPT-medium\", help='The name or path of the model to use.')\n",
        "    parser.add_argument('--lora', type=str, default=None, help='The path to the LORA adapter to use')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='Use GPU if available')\n",
        "    args = parser.parse_args(args=[])\n",
        "    eliza_interface = ElizaInterface(args.model, lora_weights=args.lora, use_gpu=args.use_gpu)\n",
        "    eliza_interface.display()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "b99153eba5714eaaa0b372debef2a169",
            "0414e8f390d645339e2b62d80d6b6c9a",
            "5b53409259f14832af044996c267516d",
            "4de5531a7abb474bb4cd1dc6b4c16f4a",
            "d2ef367389f2429ba51e176f9d057016",
            "596d090d195141aab409498e7df6d84f",
            "237710da57f244efbfa892bb031b260f",
            "5316d15550fb445c9f87ae9776b94608",
            "e108928cccbb4b90a8e0f4f5f5bfe069",
            "cc1c16ef8b524f3b908dea2f701959ad",
            "f11f39c88e234cb486ee84f6fa5d44c8",
            "25d877a0026f4b0fbb33d296b01a036c",
            "b46d5b794a2b47ba81e29bb904284614",
            "e6ab9f6d234f4eafa287b6e41a129a58",
            "4d02d6381fb34f188f6e6ea2442fef1b",
            "4ed4ab5eca6849c9bdf410f97f1cfa31",
            "9a36d922b97b4b2b8f86060e940a6783",
            "a864f541f1b2450c8b64b1df60ed3ec1",
            "b97354f56bbb4ca5b34ae7f955f33f61",
            "03fb082b9bcc44f9a6242368a9064dd8"
          ]
        },
        "id": "9TSTcj1p_ylL",
        "outputId": "e68af773-b656-4284-8d5b-a8f61f874e19"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully logged in to Hugging Face!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Output(), HBox(children=(Text(value='', description='You:', placeholder='Type your message here…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b99153eba5714eaaa0b372debef2a169"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/eliza/eliza_chat.py\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from utils.text_utils import remove_extra_spaces_and_line_breaks\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from IPython.display import Javascript\n",
        "import asyncio\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "def load_model(model_name_or_path, accelerator, lora_weights=None):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16 if accelerator.device.type == \"cuda\" else torch.float32)\n",
        "    if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "            model.config.pad_token_id = model.config.eos_token_id\n",
        "    if lora_weights:\n",
        "        config = LoraConfig(\n",
        "            task_type=TaskType.CAUSAL_LM,\n",
        "            inference_mode=True,\n",
        "            r=8,\n",
        "            lora_alpha=32,\n",
        "            lora_dropout=0.05,\n",
        "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "        )\n",
        "\n",
        "        model = get_peft_model(model, config)\n",
        "        accelerator.print(\"Loading lora_weights\", lora_weights)\n",
        "        model.load_adapter(lora_weights)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "class StoppingCriteriaSub(StoppingCriteria):\n",
        "    def __init__(self, stops = [], encounters=1):\n",
        "        super().__init__()\n",
        "        self.stops = stops\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop in self.stops:\n",
        "            stop_tensor = torch.tensor(stop, device=input_ids.device)\n",
        "            if torch.all(input_ids[-len(stop):] == stop_tensor):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "class ElizaBot:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "        self.accelerator = Accelerator(cpu=not use_gpu)\n",
        "        self.device = self.accelerator.device\n",
        "        self.model, self.tokenizer = load_model(model_name, self.accelerator, lora_weights)\n",
        "        self.model = self.accelerator.prepare(self.model)\n",
        "        self.stop_words = [\"USER:\", \"ELIZA:\"]\n",
        "        self.stop_token_ids = []\n",
        "        for stop_word in self.stop_words:\n",
        "            encoded = self.tokenizer.encode(stop_word, add_special_tokens=False)\n",
        "            if len(encoded) > 0:\n",
        "                self.stop_token_ids.append(encoded)\n",
        "        self.chat_history = []  # Initialize chat history\n",
        "\n",
        "    def prepare_input(self, input_text):\n",
        "        prompt = \"\\n\".join(self.chat_history + [f\"USER: {input_text}\", \"ELIZA:\"])\n",
        "        encoded_input = self.tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\", return_attention_mask=True)\n",
        "        return encoded_input.to(self.device)\n",
        "\n",
        "    def generate_response(self, encoded_input, max_length=512, min_length=50, **kwargs):\n",
        "        stopping_criteria_list = StoppingCriteriaList([StoppingCriteriaSub(stops=self.stop_token_ids)])\n",
        "        with torch.no_grad():\n",
        "            output_ids = self.model.generate(input_ids=encoded_input['input_ids'], attention_mask=encoded_input['attention_mask'], max_length=max_length, min_length=min_length, stopping_criteria=stopping_criteria_list, **kwargs)\n",
        "            decoded_output = self.tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "        return decoded_output\n",
        "\n",
        "    def chat(self, input_text, max_length=512, min_length=50, **kwargs):\n",
        "        input_ids = self.prepare_input(input_text)\n",
        "        output = self.generate_response(input_ids, max_length, min_length, **kwargs)\n",
        "        output = output.split(\"ELIZA:\")[-1]\n",
        "        output = remove_extra_spaces_and_line_breaks(output)\n",
        "        self.chat_history.append(f\"USER: {input_text}\")\n",
        "        self.chat_history.append(f\"ELIZA: {output}\")\n",
        "\n",
        "        return output\n",
        "\n",
        "class ElizaInterface:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "         self.eliza_bot = ElizaBot(model_name, lora_weights, use_gpu)\n",
        "         self.chat_output = widgets.Output()\n",
        "         self.input_text = widgets.Text(description=\"You:\", placeholder=\"Type your message here\")\n",
        "         self.send_button = widgets.Button(description=\"Send\")\n",
        "         self.clear_button = widgets.Button(description=\"Clear\")\n",
        "         self.stop_button = widgets.Button(description=\"Stop\")\n",
        "         self.is_running = True\n",
        "         self.send_button.on_click(self.on_send)\n",
        "         self.clear_button.on_click(self.on_clear)\n",
        "         self.stop_button.on_click(self.on_stop)\n",
        "         self.chat_display = widgets.VBox([self.chat_output,widgets.HBox([self.input_text, self.send_button]), widgets.HBox([self.clear_button, self.stop_button])])\n",
        "    def on_send(self, _):\n",
        "        if not self.is_running:\n",
        "           return\n",
        "        user_input = self.input_text.value\n",
        "        self.input_text.value = ''  # Clear the input text\n",
        "        if user_input:\n",
        "           with self.chat_output:\n",
        "               print(f\"You: {user_input}\")\n",
        "               response = self.eliza_bot.chat(user_input)\n",
        "               print(f\"Eliza: {response}\")\n",
        "\n",
        "    def on_clear(self, _):\n",
        "        self.eliza_bot.chat_history = []\n",
        "        with self.chat_output:\n",
        "           clear_output()\n",
        "\n",
        "    def on_stop(self, _):\n",
        "        self.is_running = False\n",
        "        self.send_button.disabled = True\n",
        "        with self.chat_output:\n",
        "          print(\"Eliza is not listening, restart by re-running the whole script.\")\n",
        "\n",
        "    def display(self):\n",
        "        self.hf_token = userdata.get('HF_TOKEN')\n",
        "        if self.hf_token:\n",
        "          login(self.hf_token)\n",
        "          print(\"Successfully logged in to Hugging Face!\")\n",
        "        else:\n",
        "           print(\"Token is not set. Please save the token first.\")\n",
        "        display(self.chat_display)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Run the Eliza chatbot.')\n",
        "    parser.add_argument('--model', type=str, default=\"microsoft/DialoGPT-medium\", help='The name or path of the model to use.')\n",
        "    parser.add_argument('--lora', type=str, default=None, help='The path to the LORA adapter to use')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='Use GPU if available')\n",
        "    args = parser.parse_args(args=[])\n",
        "    eliza_interface = ElizaInterface(args.model, lora_weights=args.lora, use_gpu=args.use_gpu)\n",
        "    eliza_interface.display()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1ILSTbT_5sg",
        "outputId": "254e20e4-4d80-4c5c-880a-9169305ed287"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/eliza/eliza_chat.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/eliza/eliza_chat.py --model \"microsoft/DialoGPT-medium\" --use_gpu False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taknHVQWADn2",
        "outputId": "fb8cc657-65de-4149-ebde-b8c7a203e899"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-02-03 04:11:45.761492: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1738555905.913859   15181 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1738555905.957435   15181 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/eliza/eliza_chat.py\", line 139, in <module>\n",
            "    eliza_interface.display()\n",
            "  File \"/content/eliza/eliza_chat.py\", line 123, in display\n",
            "    self.hf_token = userdata.get('HF_TOKEN')\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/userdata.py\", line 62, in get\n",
            "    resp = _message.blocking_request(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\", line 173, in blocking_request\n",
            "    request_id = send_request(\n",
            "                 ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\", line 117, in send_request\n",
            "    instance = ipython.get_kernelapp()\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_ipython.py\", line 28, in get_kernelapp\n",
            "    return get_ipython().kernel.parent\n",
            "           ^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'NoneType' object has no attribute 'kernel'\n",
            "Process Process-auto_conversion:\n",
            "Exception ignored in atexit callback: <function _exit_function at 0x7d55f4f3afc0>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/util.py\", line 360, in _exit_function\n",
            "    p.join()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 43, in wait\n",
            "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/multiprocessing/popen_fork.py\", line 27, in poll\n",
            "    pid, sts = os.waitpid(self.pid, flag)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/safetensors_conversion.py\", line 84, in auto_conversion\n",
            "    sha = get_conversion_pr_reference(api, pretrained_model_name_or_path, **cached_file_kwargs)\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/safetensors_conversion.py\", line 71, in get_conversion_pr_reference\n",
            "    spawn_conversion(token, private, model_id)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/safetensors_conversion.py\", line 47, in spawn_conversion\n",
            "    result = requests.post(sse_url, stream=True, json=data).json()\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 115, in post\n",
            "    return request(\"post\", url, data=data, json=json, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/api.py\", line 59, in request\n",
            "    return session.request(method=method, url=url, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 589, in request\n",
            "    resp = self.send(prep, **send_kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/sessions.py\", line 703, in send\n",
            "    r = adapter.send(request, **kwargs)\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/requests/adapters.py\", line 667, in send\n",
            "    resp = conn.urlopen(\n",
            "           ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 787, in urlopen\n",
            "    response = self._make_request(\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connectionpool.py\", line 534, in _make_request\n",
            "    response = conn.getresponse()\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/urllib3/connection.py\", line 516, in getresponse\n",
            "    httplib_response = super().getresponse()\n",
            "                       ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 1395, in getresponse\n",
            "    response.begin()\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 325, in begin\n",
            "    version, status, reason = self._read_status()\n",
            "                              ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/http/client.py\", line 286, in _read_status\n",
            "    line = str(self.fp.readline(_MAXLINE + 1), \"iso-8859-1\")\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/socket.py\", line 718, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1314, in recv_into\n",
            "    return self.read(nbytes, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/ssl.py\", line 1166, in read\n",
            "    return self._sslobj.read(len, buffer)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from utils.text_utils import remove_extra_spaces_and_line_breaks\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from IPython.display import Javascript\n",
        "import asyncio\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"TRANSFORMERS_SAFETENSORS_CONVERSION\"] = \"false\"\n",
        "\n",
        "def load_model(model_name_or_path, accelerator, lora_weights=None):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16 if accelerator.device.type == \"cuda\" else torch.float32)\n",
        "    if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "            model.config.pad_token_id = model.config.eos_token_id\n",
        "    if lora_weights:\n",
        "        config = LoraConfig(\n",
        "            task_type=TaskType.CAUSAL_LM,\n",
        "            inference_mode=True,\n",
        "            r=8,\n",
        "            lora_alpha=32,\n",
        "            lora_dropout=0.05,\n",
        "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "        )\n",
        "\n",
        "        model = get_peft_model(model, config)\n",
        "        accelerator.print(\"Loading lora_weights\", lora_weights)\n",
        "        model.load_adapter(lora_weights)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "class StoppingCriteriaSub(StoppingCriteria):\n",
        "    def __init__(self, stops = [], encounters=1):\n",
        "        super().__init__()\n",
        "        self.stops = stops\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop in self.stops:\n",
        "            stop_tensor = torch.tensor(stop, device=input_ids.device)\n",
        "            if torch.all(input_ids[-len(stop):] == stop_tensor):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "class ElizaBot:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "        self.accelerator = Accelerator(cpu=not use_gpu)\n",
        "        self.device = self.accelerator.device\n",
        "        self.model, self.tokenizer = load_model(model_name, self.accelerator, lora_weights)\n",
        "        self.model = self.accelerator.prepare(self.model)\n",
        "        self.stop_words = [\"USER:\", \"ELIZA:\"]\n",
        "        self.stop_token_ids = []\n",
        "        for stop_word in self.stop_words:\n",
        "            encoded = self.tokenizer.encode(stop_word, add_special_tokens=False)\n",
        "            if len(encoded) > 0:\n",
        "                self.stop_token_ids.append(encoded)\n",
        "        self.chat_history = []  # Initialize chat history\n",
        "\n",
        "    def prepare_input(self, input_text):\n",
        "        prompt = \"\\n\".join(self.chat_history + [f\"USER: {input_text}\", \"ELIZA:\"])\n",
        "        encoded_input = self.tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\", return_attention_mask=True)\n",
        "        return encoded_input.to(self.device)\n",
        "\n",
        "    def generate_response(self, encoded_input, max_length=512, min_length=50, **kwargs):\n",
        "        stopping_criteria_list = StoppingCriteriaList([StoppingCriteriaSub(stops=self.stop_token_ids)])\n",
        "        with torch.no_grad():\n",
        "            output_ids = self.model.generate(input_ids=encoded_input['input_ids'], attention_mask=encoded_input['attention_mask'], max_length=max_length, min_length=min_length, stopping_criteria=stopping_criteria_list, **kwargs)\n",
        "            decoded_output = self.tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "        return decoded_output\n",
        "\n",
        "    def chat(self, input_text, max_length=512, min_length=50, **kwargs):\n",
        "        input_ids = self.prepare_input(input_text)\n",
        "        output = self.generate_response(input_ids, max_length, min_length, **kwargs)\n",
        "        output = output.split(\"ELIZA:\")[-1]\n",
        "        output = remove_extra_spaces_and_line_breaks(output)\n",
        "        self.chat_history.append(f\"USER: {input_text}\")\n",
        "        self.chat_history.append(f\"ELIZA: {output}\")\n",
        "\n",
        "        return output\n",
        "\n",
        "class ElizaInterface:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "         self.eliza_bot = ElizaBot(model_name, lora_weights, use_gpu)\n",
        "         self.chat_output = widgets.Output()\n",
        "         self.input_text = widgets.Text(description=\"You:\", placeholder=\"Type your message here\")\n",
        "         self.send_button = widgets.Button(description=\"Send\")\n",
        "         self.clear_button = widgets.Button(description=\"Clear\")\n",
        "         self.stop_button = widgets.Button(description=\"Stop\")\n",
        "         self.is_running = True\n",
        "         self.send_button.on_click(self.on_send)\n",
        "         self.clear_button.on_click(self.on_clear)\n",
        "         self.stop_button.on_click(self.on_stop)\n",
        "         self.chat_display = widgets.VBox([self.chat_output,widgets.HBox([self.input_text, self.send_button]), widgets.HBox([self.clear_button, self.stop_button])])\n",
        "    def on_send(self, _):\n",
        "        if not self.is_running:\n",
        "           return\n",
        "        user_input = self.input_text.value\n",
        "        self.input_text.value = ''  # Clear the input text\n",
        "        if user_input:\n",
        "           with self.chat_output:\n",
        "               print(f\"You: {user_input}\")\n",
        "               response = self.eliza_bot.chat(user_input)\n",
        "               print(f\"Eliza: {response}\")\n",
        "\n",
        "    def on_clear(self, _):\n",
        "        self.eliza_bot.chat_history = []\n",
        "        with self.chat_output:\n",
        "           clear_output()\n",
        "\n",
        "    def on_stop(self, _):\n",
        "        self.is_running = False\n",
        "        self.send_button.disabled = True\n",
        "        with self.chat_output:\n",
        "          print(\"Eliza is not listening, restart by re-running the whole script.\")\n",
        "\n",
        "    def display(self):\n",
        "        self.hf_token = userdata.get('HF_TOKEN')\n",
        "        if self.hf_token:\n",
        "          login(token=self.hf_token)\n",
        "          print(\"Successfully logged in to Hugging Face!\")\n",
        "        else:\n",
        "           print(\"Token is not set. Please save the token first.\")\n",
        "        display(self.chat_display)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Run the Eliza chatbot.')\n",
        "    parser.add_argument('--model', type=str, default=\"microsoft/DialoGPT-medium\", help='The name or path of the model to use.')\n",
        "    parser.add_argument('--lora', type=str, default=None, help='The path to the LORA adapter to use')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='Use GPU if available')\n",
        "    args = parser.parse_args(args=[])\n",
        "    eliza_interface = ElizaInterface(args.model, lora_weights=args.lora, use_gpu=args.use_gpu)\n",
        "    eliza_interface.display()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524,
          "referenced_widgets": [
            "c8f7c564f15f4625b9af3b837df2dab7",
            "745f0dfc29054c7c881c347d8c973858",
            "fe587d2f2da04703b510419d1cd3e778",
            "4a9c145c83384c9a88e6594a81ffd2d2",
            "b00b8d9990f1472ab99f2e67db3cd1c4",
            "dd650e021ae5499eb82b00ff2640a4e8",
            "28126ac8c8bb4794908d0c765cbc309c",
            "dd232112b1274a36a7eba53c0db07b3b",
            "b02bb45c6d964a6aa43bf6e9fcde7d8f",
            "8f54c7b338484b5d92d7071d89fcf459",
            "87e692cd03d146c5bb679ce98320cd6a",
            "855a915e9d664104bccf87b0cab791d6",
            "4d83ce12adc34c5593a68a98be20a5ed",
            "e0426331e33a462bb94194b9dba26e02",
            "c89bfb3408f041b18da4ee1536f2cdac",
            "dd5a87741a434597b863bd4dc83fb576",
            "05638e4dd70f4f7399f6372e3842441b",
            "59a31ba5926244888dbc365e30d7a755",
            "26ab81f089a7498996ffc215c978223d",
            "6d9feb89a21c4b44806b3cd9c6c125d9"
          ]
        },
        "id": "sLPrneZeAt4J",
        "outputId": "7f98cf0e-a799-4043-b166-b65cc789dad5"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully logged in to Hugging Face!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Output(), HBox(children=(Text(value='', description='You:', placeholder='Type your message here…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c8f7c564f15f4625b9af3b837df2dab7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/eliza/eliza_chat.py\n",
        "import argparse\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import torch\n",
        "from accelerate import Accelerator\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, StoppingCriteria, StoppingCriteriaList\n",
        "from peft import LoraConfig, get_peft_model, TaskType\n",
        "from utils.text_utils import remove_extra_spaces_and_line_breaks\n",
        "\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "from IPython.display import Javascript\n",
        "import asyncio\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"TRANSFORMERS_SAFETENSORS_CONVERSION\"] = \"false\"\n",
        "\n",
        "def load_model(model_name_or_path, accelerator, lora_weights=None):\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(model_name_or_path, torch_dtype=torch.bfloat16 if accelerator.device.type == \"cuda\" else torch.float32)\n",
        "    if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "            model.config.pad_token_id = model.config.eos_token_id\n",
        "    if lora_weights:\n",
        "        config = LoraConfig(\n",
        "            task_type=TaskType.CAUSAL_LM,\n",
        "            inference_mode=True,\n",
        "            r=8,\n",
        "            lora_alpha=32,\n",
        "            lora_dropout=0.05,\n",
        "            target_modules=[\"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\", \"gate_proj\", \"up_proj\", \"down_proj\"]\n",
        "        )\n",
        "\n",
        "        model = get_peft_model(model, config)\n",
        "        accelerator.print(\"Loading lora_weights\", lora_weights)\n",
        "        model.load_adapter(lora_weights)\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "class StoppingCriteriaSub(StoppingCriteria):\n",
        "    def __init__(self, stops = [], encounters=1):\n",
        "        super().__init__()\n",
        "        self.stops = stops\n",
        "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor, **kwargs) -> bool:\n",
        "        for stop in self.stops:\n",
        "            stop_tensor = torch.tensor(stop, device=input_ids.device)\n",
        "            if torch.all(input_ids[-len(stop):] == stop_tensor):\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "class ElizaBot:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "        self.accelerator = Accelerator(cpu=not use_gpu)\n",
        "        self.device = self.accelerator.device\n",
        "        self.model, self.tokenizer = load_model(model_name, self.accelerator, lora_weights)\n",
        "        self.model = self.accelerator.prepare(self.model)\n",
        "        self.stop_words = [\"USER:\", \"ELIZA:\"]\n",
        "        self.stop_token_ids = []\n",
        "        for stop_word in self.stop_words:\n",
        "            encoded = self.tokenizer.encode(stop_word, add_special_tokens=False)\n",
        "            if len(encoded) > 0:\n",
        "                self.stop_token_ids.append(encoded)\n",
        "        self.chat_history = []  # Initialize chat history\n",
        "\n",
        "    def prepare_input(self, input_text):\n",
        "        prompt = \"\\n\".join(self.chat_history + [f\"USER: {input_text}\", \"ELIZA:\"])\n",
        "        encoded_input = self.tokenizer.encode(prompt, add_special_tokens=True, return_tensors=\"pt\", return_attention_mask=True)\n",
        "        return encoded_input.to(self.device)\n",
        "\n",
        "    def generate_response(self, encoded_input, max_length=512, min_length=50, **kwargs):\n",
        "        stopping_criteria_list = StoppingCriteriaList([StoppingCriteriaSub(stops=self.stop_token_ids)])\n",
        "        with torch.no_grad():\n",
        "            output_ids = self.model.generate(input_ids=encoded_input['input_ids'], attention_mask=encoded_input['attention_mask'], max_length=max_length, min_length=min_length, stopping_criteria=stopping_criteria_list, **kwargs)\n",
        "            decoded_output = self.tokenizer.decode(output_ids, skip_special_tokens=True)\n",
        "        return decoded_output\n",
        "\n",
        "    def chat(self, input_text, max_length=512, min_length=50, **kwargs):\n",
        "        input_ids = self.prepare_input(input_text)\n",
        "        output = self.generate_response(input_ids, max_length, min_length, **kwargs)\n",
        "        output = output.split(\"ELIZA:\")[-1]\n",
        "        output = remove_extra_spaces_and_line_breaks(output)\n",
        "        self.chat_history.append(f\"USER: {input_text}\")\n",
        "        self.chat_history.append(f\"ELIZA: {output}\")\n",
        "\n",
        "        return output\n",
        "\n",
        "class ElizaInterface:\n",
        "    def __init__(self, model_name, lora_weights=None, use_gpu=True):\n",
        "         self.eliza_bot = ElizaBot(model_name, lora_weights, use_gpu)\n",
        "         self.chat_output = widgets.Output()\n",
        "         self.input_text = widgets.Text(description=\"You:\", placeholder=\"Type your message here\")\n",
        "         self.send_button = widgets.Button(description=\"Send\")\n",
        "         self.clear_button = widgets.Button(description=\"Clear\")\n",
        "         self.stop_button = widgets.Button(description=\"Stop\")\n",
        "         self.is_running = True\n",
        "         self.send_button.on_click(self.on_send)\n",
        "         self.clear_button.on_click(self.on_clear)\n",
        "         self.stop_button.on_click(self.on_stop)\n",
        "         self.chat_display = widgets.VBox([self.chat_output,widgets.HBox([self.input_text, self.send_button]), widgets.HBox([self.clear_button, self.stop_button])])\n",
        "    def on_send(self, _):\n",
        "        if not self.is_running:\n",
        "           return\n",
        "        user_input = self.input_text.value\n",
        "        self.input_text.value = ''  # Clear the input text\n",
        "        if user_input:\n",
        "           with self.chat_output:\n",
        "               print(f\"You: {user_input}\")\n",
        "               response = self.eliza_bot.chat(user_input)\n",
        "               print(f\"Eliza: {response}\")\n",
        "\n",
        "    def on_clear(self, _):\n",
        "        self.eliza_bot.chat_history = []\n",
        "        with self.chat_output:\n",
        "           clear_output()\n",
        "\n",
        "    def on_stop(self, _):\n",
        "        self.is_running = False\n",
        "        self.send_button.disabled = True\n",
        "        with self.chat_output:\n",
        "          print(\"Eliza is not listening, restart by re-running the whole script.\")\n",
        "\n",
        "    def display(self):\n",
        "        self.hf_token = userdata.get('HF_TOKEN')\n",
        "        if self.hf_token:\n",
        "          login(token=self.hf_token)\n",
        "          print(\"Successfully logged in to Hugging Face!\")\n",
        "        else:\n",
        "           print(\"Token is not set. Please save the token first.\")\n",
        "        display(self.chat_display)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser(description='Run the Eliza chatbot.')\n",
        "    parser.add_argument('--model', type=str, default=\"microsoft/DialoGPT-medium\", help='The name or path of the model to use.')\n",
        "    parser.add_argument('--lora', type=str, default=None, help='The path to the LORA adapter to use')\n",
        "    parser.add_argument('--use_gpu', type=bool, default=True, help='Use GPU if available')\n",
        "    args = parser.parse_args(args=[])\n",
        "    eliza_interface = ElizaInterface(args.model, lora_weights=args.lora, use_gpu=args.use_gpu)\n",
        "    eliza_interface.display()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZM6Yx_m9A2sB",
        "outputId": "19538a5c-9135-4a4b-d91e-421e6502e70f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/eliza/eliza_chat.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --force-reinstall pip\n"
      ],
      "metadata": {
        "id": "Bm2vEJScCoXx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}